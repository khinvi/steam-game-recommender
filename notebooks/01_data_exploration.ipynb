{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Game Recommender System - Data Exploration\n",
    "\n",
    "This notebook explores the Steam dataset, examining its structure and characteristics to inform our recommendation system design. We'll analyze user behavior patterns, game popularity distributions, and user-game interactions.\n",
    "\n",
    "## Setup and Data Loading\n",
    "\n",
    "First, let's import necessary libraries and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Create data directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to load the data. We'll create a fallback mechanism in case the project structure isn't fully set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sample_size=None):\n",
    "    \"\"\"\n",
    "    Load the Steam dataset files (reviews and items).\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Number of reviews to sample (for faster processing)\n",
    "        \n",
    "    Returns:\n",
    "        reviews_df: DataFrame containing user reviews/interactions\n",
    "        items_df: DataFrame containing game metadata\n",
    "    \"\"\"\n",
    "    # Define file paths - try multiple possible locations\n",
    "    possible_paths = [\n",
    "        ('../data/reviews_v2.json.gz', '../data/items_v2.json.gz'),\n",
    "        ('../data/steam_reviews.json.gz', '../data/steam_games.json.gz'),\n",
    "        ('data/reviews_v2.json.gz', 'data/items_v2.json.gz'),\n",
    "        ('data/steam_reviews.json.gz', 'data/steam_games.json.gz')\n",
    "    ]\n",
    "    \n",
    "    # Try to find the data files\n",
    "    reviews_path, items_path = None, None\n",
    "    for r_path, i_path in possible_paths:\n",
    "        if os.path.exists(r_path) and os.path.exists(i_path):\n",
    "            reviews_path, items_path = r_path, i_path\n",
    "            break\n",
    "    \n",
    "    if reviews_path is None:\n",
    "        raise FileNotFoundError(\"Could not find data files. Please check paths.\")\n",
    "        \n",
    "    print(f\"Loading reviews from {reviews_path}\")\n",
    "    print(f\"Loading items from {items_path}\")\n",
    "    \n",
    "    # Load reviews data\n",
    "    reviews = []\n",
    "    with gzip.open(reviews_path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(tqdm(f, desc=\"Loading reviews\")):\n",
    "            if sample_size is not None and i >= sample_size:\n",
    "                break\n",
    "            try:\n",
    "                reviews.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    # Load items data\n",
    "    items = []\n",
    "    with gzip.open(items_path, 'rt', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Loading items\"):\n",
    "            try:\n",
    "                items.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    reviews_df = pd.DataFrame(reviews)\n",
    "    items_df = pd.DataFrame(items)\n",
    "    \n",
    "    return reviews_df, items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load a sample of the data for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample of the data for faster exploration (50,000 reviews)\n",
    "# Set to None to load the full dataset (may take significant time)\n",
    "SAMPLE_SIZE = 50000\n",
    "\n",
    "try:\n",
    "    reviews_df, items_df = load_data(sample_size=SAMPLE_SIZE)\n",
    "    print(f\"Loaded {len(reviews_df)} reviews and {len(items_df)} items.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Creating sample data for demonstration purposes...\")\n",
    "    \n",
    "    # Create synthetic data for demonstration if real data is unavailable\n",
    "    import random\n",
    "    \n",
    "    # Create sample reviews\n",
    "    n_users = 1000\n",
    "    n_games = 500\n",
    "    n_reviews = 10000\n",
    "    \n",
    "    user_ids = [f\"user_{i}\" for i in range(n_users)]\n",
    "    game_ids = [f\"game_{i}\" for i in range(n_games)]\n",
    "    \n",
    "    reviews = []\n",
    "    for _ in range(n_reviews):\n",
    "        user_id = random.choice(user_ids)\n",
    "        game_id = random.choice(game_ids)\n",
    "        playtime = random.randint(0, 1000) if random.random() > 0.2 else 0\n",
    "        reviews.append({\n",
    "            'user_id': user_id,\n",
    "            'item_id': game_id,\n",
    "            'playtime_forever': playtime,\n",
    "            'playtime_2weeks': min(playtime, random.randint(0, 20)) if playtime > 0 else 0\n",
    "        })\n",
    "    \n",
    "    # Create sample games\n",
    "    game_names = [f\"Game Title {i}\" for i in range(n_games)]\n",
    "    genres = ['Action', 'Adventure', 'RPG', 'Strategy', 'Simulation', 'Sports', 'Racing', 'Puzzle']\n",
    "    \n",
    "    items = []\n",
    "    for i in range(n_games):\n",
    "        n_genres = random.randint(1, 3)\n",
    "        game_genres = random.sample(genres, n_genres)\n",
    "        items.append({\n",
    "            'item_id': game_ids[i],\n",
    "            'item_name': game_names[i],\n",
    "            'genres': game_genres\n",
    "        })\n",
    "    \n",
    "    reviews_df = pd.DataFrame(reviews)\n",
    "    items_df = pd.DataFrame(items)\n",
    "    \n",
    "    print(f\"Created {len(reviews_df)} synthetic reviews and {len(items_df)} synthetic items.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration\n",
    "\n",
    "Let's examine the structure and content of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the reviews dataset\n",
    "print(\"Reviews Dataset:\")\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the items dataset\n",
    "print(\"Items Dataset:\")\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the reviews DataFrame\n",
    "print(\"Reviews DataFrame Info:\")\n",
    "reviews_df.info()\n",
    "\n",
    "# Check for missing values in reviews\n",
    "print(\"\\nMissing values in reviews:\")\n",
    "print(reviews_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the items DataFrame\n",
    "print(\"Items DataFrame Info:\")\n",
    "items_df.info()\n",
    "\n",
    "# Check for missing values in items\n",
    "print(\"\\nMissing values in items:\")\n",
    "print(items_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute some basic statistics about the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "n_users = reviews_df['user_id'].nunique()\n",
    "n_games = reviews_df['item_id'].nunique()\n",
    "n_interactions = len(reviews_df)\n",
    "sparsity = 100 * (1 - (n_interactions / (n_users * n_games)))\n",
    "\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of unique games: {n_games}\")\n",
    "print(f\"Number of interactions: {n_interactions}\")\n",
    "print(f\"Matrix sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Activity Analysis\n",
    "\n",
    "Let's analyze user activity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interactions per user\n",
    "user_interactions = reviews_df['user_id'].value_counts()\n",
    "\n",
    "# Plot the distribution of interactions per user\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(user_interactions, log_scale=True, bins=50)\n",
    "plt.title('Distribution of Games per User (Log Scale)')\n",
    "plt.xlabel('Number of Games')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "user_interactions_stats = user_interactions.describe()\n",
    "print(\"Summary statistics for games per user:\")\n",
    "print(user_interactions_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total playtime per user\n",
    "user_playtime = reviews_df.groupby('user_id')['playtime_forever'].sum()\n",
    "\n",
    "# Plot the distribution of total playtime per user\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(user_playtime[user_playtime > 0], log_scale=True, bins=50)\n",
    "plt.title('Distribution of Total Playtime per User (Log Scale)')\n",
    "plt.xlabel('Total Playtime (minutes)')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "user_playtime_stats = user_playtime.describe()\n",
    "print(\"Summary statistics for total playtime per user:\")\n",
    "print(user_playtime_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Popularity Analysis\n",
    "\n",
    "Let's examine the popularity of games based on the number of users and playtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate interactions per game\n",
    "game_interactions = reviews_df['item_id'].value_counts()\n",
    "\n",
    "# Plot the distribution of interactions per game\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(game_interactions, log_scale=True, bins=50)\n",
    "plt.title('Distribution of Users per Game (Log Scale)')\n",
    "plt.xlabel('Number of Users')\n",
    "plt.ylabel('Number of Games')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "game_interactions_stats = game_interactions.describe()\n",
    "print(\"Summary statistics for users per game:\")\n",
    "print(game_interactions_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total playtime per game\n",
    "game_playtime = reviews_df.groupby('item_id')['playtime_forever'].sum()\n",
    "\n",
    "# Plot the distribution of total playtime per game\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(game_playtime[game_playtime > 0], log_scale=True, bins=50)\n",
    "plt.title('Distribution of Total Playtime per Game (Log Scale)')\n",
    "plt.xlabel('Total Playtime (minutes)')\n",
    "plt.ylabel('Number of Games')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "game_playtime_stats = game_playtime.describe()\n",
    "print(\"Summary statistics for total playtime per game:\")\n",
    "print(game_playtime_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Games Analysis\n",
    "\n",
    "Let's identify the most popular games based on number of users and playtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reviews with items to get game names\n",
    "merged_df = reviews_df.merge(items_df, on='item_id', how='left')\n",
    "\n",
    "# Top games by number of users\n",
    "top_games_by_users = merged_df.groupby(['item_id', 'item_name']).size().reset_index(name='user_count')\n",
    "top_games_by_users = top_games_by_users.sort_values('user_count', ascending=False).head(20)\n",
    "\n",
    "# Plot top games by users\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_games_by_users, x='user_count', y='item_name', palette='viridis')\n",
    "plt.title('Top 20 Games by Number of Users')\n",
    "plt.xlabel('Number of Users')\n",
    "plt.ylabel('Game Title')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top games by total playtime\n",
    "top_games_by_playtime = merged_df.groupby(['item_id', 'item_name'])['playtime_forever'].sum().reset_index()\n",
    "top_games_by_playtime = top_games_by_playtime.sort_values('playtime_forever', ascending=False).head(20)\n",
    "\n",
    "# Convert playtime to hours for better readability\n",
    "top_games_by_playtime['playtime_hours'] = top_games_by_playtime['playtime_forever'] / 60\n",
    "\n",
    "# Plot top games by playtime\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_games_by_playtime, x='playtime_hours', y='item_name', palette='viridis')\n",
    "plt.title('Top 20 Games by Total Playtime')\n",
    "plt.xlabel('Total Playtime (hours)')\n",
    "plt.ylabel('Game Title')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Playtime Analysis\n",
    "\n",
    "Let's examine the average playtime per game, which might be a better indicator of engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average playtime per game\n",
    "avg_playtime = merged_df.groupby(['item_id', 'item_name'])['playtime_forever'].mean().reset_index()\n",
    "avg_playtime = avg_playtime[avg_playtime['playtime_forever'] > 0]  # Filter out zero playtime\n",
    "avg_playtime = avg_playtime.sort_values('playtime_forever', ascending=False).head(20)\n",
    "\n",
    "# Convert to hours\n",
    "avg_playtime['avg_playtime_hours'] = avg_playtime['playtime_forever'] / 60\n",
    "\n",
    "# Plot top games by average playtime\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=avg_playtime, x='avg_playtime_hours', y='item_name', palette='viridis')\n",
    "plt.title('Top 20 Games by Average Playtime per User')\n",
    "plt.xlabel('Average Playtime (hours)')\n",
    "plt.ylabel('Game Title')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Game Interaction Matrix Analysis\n",
    "\n",
    "Let's analyze the sparsity of the user-game interaction matrix, which is a key factor for recommendation system design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller sample for visualization\n",
    "top_users = reviews_df['user_id'].value_counts().head(50).index.tolist()\n",
    "top_games = reviews_df['item_id'].value_counts().head(50).index.tolist()\n",
    "\n",
    "# Filter the reviews for top users and games\n",
    "sample_interactions = reviews_df[\n",
    "    (reviews_df['user_id'].isin(top_users)) & \n",
    "    (reviews_df['item_id'].isin(top_games))\n",
    "]\n",
    "\n",
    "# Create a binary interaction matrix\n",
    "interaction_matrix = sample_interactions.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='item_id',\n",
    "    values='playtime_forever',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Convert to binary (played or not played)\n",
    "binary_matrix = (interaction_matrix > 0).astype(int)\n",
    "\n",
    "# Visualize the matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(binary_matrix, cmap='viridis', cbar_kws={'label': 'Interaction'})\n",
    "plt.title('User-Game Interaction Matrix (Sample of Top 50 Users and Games)')\n",
    "plt.xlabel('Game ID')\n",
    "plt.ylabel('User ID')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate sparsity of this sample\n",
    "sample_sparsity = 100 * (1 - binary_matrix.sum().sum() / (binary_matrix.shape[0] * binary_matrix.shape[1]))\n",
    "print(f\"Sparsity of the sample matrix: {sample_sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playtime Distribution Analysis\n",
    "\n",
    "Let's take a closer look at how playtime is distributed across users and games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out zero playtimes for a more meaningful analysis\n",
    "non_zero_playtime = reviews_df[reviews_df['playtime_forever'] > 0]\n",
    "\n",
    "# Histogram of playtime (log scale)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(non_zero_playtime['playtime_forever'], log_scale=True, bins=50)\n",
    "plt.title('Distribution of Playtime (Log Scale)')\n",
    "plt.xlabel('Playtime (minutes)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Statistics of playtime\n",
    "playtime_stats = non_zero_playtime['playtime_forever'].describe()\n",
    "print(\"Playtime statistics (minutes):\")\n",
    "print(playtime_stats)\n",
    "\n",
    "# Convert to hours for better interpretability\n",
    "playtime_hours_stats = non_zero_playtime['playtime_forever'].div(60).describe()\n",
    "print(\"\\nPlaytime statistics (hours):\")\n",
    "print(playtime_hours_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Behavior Patterns\n",
    "\n",
    "Let's analyze how users interact with games over time, which could inform our recommendation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze recent vs. total playtime (if 'playtime_2weeks' is available)\n",
    "if 'playtime_2weeks' in reviews_df.columns:\n",
    "    # Filter for users who played within the last two weeks\n",
    "    recent_players = reviews_df[reviews_df['playtime_2weeks'] > 0]\n",
    "    \n",
    "    # Calculate percentage of recent playtime relative to total playtime\n",
    "    recent_players['playtime_percentage'] = 100 * recent_players['playtime_2weeks'] / recent_players['playtime_forever']\n",
    "    \n",
    "    # Plot the distribution of recent playtime percentage\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(recent_players['playtime_percentage'].clip(0, 100), bins=50)\n",
    "    plt.title('Recent Playtime as Percentage of Total Playtime')\n",
    "    plt.xlabel('Recent Playtime Percentage')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    recent_stats = recent_players['playtime_percentage'].describe()\n",
    "    print(\"Recent playtime percentage statistics:\")\n",
    "    print(recent_stats)\n",
    "    \n",
    "    # Find games with high percentage of recent playtime\n",
    "    recent_game_avg = recent_players.groupby('item_id')['playtime_percentage'].mean().reset_index()\n",
    "    recent_game_avg = recent_game_avg.merge(items_df[['item_id', 'item_name']], on='item_id', how='left')\n",
    "    recent_game_avg = recent_game_avg.sort_values('playtime_percentage', ascending=False).head(20)\n",
    "    \n",
    "    # Plot games with highest recent playtime percentage\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=recent_game_avg, x='playtime_percentage', y='item_name', palette='viridis')\n",
    "    plt.title('Top 20 Games by Recent Playtime Percentage')\n",
    "    plt.xlabel('Average Recent Playtime Percentage')\n",
    "    plt.ylabel('Game Title')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'playtime_2weeks' column not available in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Genre Analysis\n",
    "\n",
    "If the dataset includes genre information, let's analyze the distribution of game genres and user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if genres are available in the items dataframe\n",
    "# Check if genres are available in the items dataframe
    if 'genres' in items_df.columns:
        # Extract all genres and count their occurrences
        all_genres = []
        
        for genres_list in items_df['genres'].dropna():
            if isinstance(genres_list, list):
                all_genres.extend(genres_list)
            elif isinstance(genres_list, str):
                # Handle case where genres might be stored as a string
                try:
                    genres_json = json.loads(genres_list.replace("'", "\""))
                    if isinstance(genres_json, list):
                        all_genres.extend(genres_json)
                except:
                    pass
        
        # Count genre occurrences
        genre_counts = Counter(all_genres)
        
        # Plot top genres
        top_genres = pd.DataFrame({
            'genre': list(genre_counts.keys()),
            'count': list(genre_counts.values())
        }).sort_values('count', ascending=False).head(20)
        
        plt.figure(figsize=(12, 8))
        sns.barplot(data=top_genres, x='count', y='genre', palette='viridis')
        plt.title('Top 20 Game Genres')
        plt.xlabel('Number of Games')
        plt.ylabel('Genre')
        plt.tight_layout()
        plt.show()
        
        # Analyze playtime by genre
        if not merged_df.empty and 'genres' in merged_df.columns:
            # Create a new dataframe with one row per game-genre combination
            genre_playtime = []
            
            for _, row in merged_df.iterrows():
                if pd.notna(row['genres']):
                    genres = row['genres']
                    if isinstance(genres, list):
                        for genre in genres:
                            genre_playtime.append({
                                'genre': genre,
                                'playtime_forever': row['playtime_forever']
                            })
                    elif isinstance(genres, str):
                        try:
                            genres_json = json.loads(genres.replace("'", "\""))
                            if isinstance(genres_json, list):
                                for genre in genres_json:
                                    genre_playtime.append({
                                        'genre': genre,
                                        'playtime_forever': row['playtime_forever']
                                    })
                        except:
                            pass
            
            genre_playtime_df = pd.DataFrame(genre_playtime)
            
            # Calculate average playtime per genre
            avg_playtime_by_genre = genre_playtime_df.groupby('genre')['playtime_forever'].mean().reset_index()
            avg_playtime_by_genre = avg_playtime_by_genre.sort_values('playtime_forever', ascending=False).head(20)
            
            # Convert to hours
            avg_playtime_by_genre['avg_playtime_hours'] = avg_playtime_by_genre['playtime_forever'] / 60
            
            # Plot average playtime by genre
            plt.figure(figsize=(12, 8))
            sns.barplot(data=avg_playtime_by_genre, x='avg_playtime_hours', y='genre', palette='viridis')
            plt.title('Top 20 Genres by Average Playtime')
            plt.xlabel('Average Playtime (hours)')
            plt.ylabel('Genre')
            plt.tight_layout()
            plt.show()
    else:
        print("Genre information not available in the dataset.")
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Similarity Analysis\n",
    "\n",
    "Let's analyze user similarity based on their game libraries, which is fundamental for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Sample a small number of users for analysis\n",
    "sample_size = min(100, n_users)\n",
    "sample_users = np.random.choice(reviews_df['user_id'].unique(), sample_size, replace=False)\n",
    "\n",
    "# Create a dictionary mapping users to their game libraries\n",
    "user_games = {}\n",
    "for user in sample_users:\n",
    "    user_games[user] = set(reviews_df[reviews_df['user_id'] == user]['item_id'])\n",
    "\n",
    "# Calculate pairwise similarities\n",
    "similarities = []\n",
    "for i, user1 in enumerate(sample_users):\n",
    "    for user2 in sample_users[i+1:]:\n",
    "        sim = jaccard_similarity(user_games[user1], user_games[user2])\n",
    "        similarities.append(sim)\n",
    "\n",
    "# Plot the distribution of user similarities\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(similarities, bins=50)\n",
    "plt.title('Distribution of Jaccard Similarity Between User Game Libraries')\n",
    "plt.xlabel('Jaccard Similarity')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate statistics\n",
    "sim_stats = pd.Series(similarities).describe()\n",
    "print(\"Statistics of user-user similarities:\")\n",
    "print(sim_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Similarity Analysis\n",
    "\n",
    "Similarly, let's analyze how games are related to each other based on user libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a small number of games for analysis\n",
    "sample_size = min(100, n_games)\n",
    "sample_games = np.random.choice(reviews_df['item_id'].unique(), sample_size, replace=False)\n",
    "\n",
    "# Create a dictionary mapping games to the users who played them\n",
    "game_users = {}\n",
    "for game in sample_games:\n",
    "    game_users[game] = set(reviews_df[reviews_df['item_id'] == game]['user_id'])\n",
    "\n",
    "# Calculate pairwise similarities\n",
    "game_similarities = []\n",
    "for i, game1 in enumerate(sample_games):\n",
    "    for game2 in sample_games[i+1:]:\n",
    "        sim = jaccard_similarity(game_users[game1], game_users[game2])\n",
    "        game_similarities.append(sim)\n",
    "\n",
    "# Plot the distribution of game similarities\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(game_similarities, bins=50)\n",
    "plt.title('Distribution of Jaccard Similarity Between Games (Based on User Overlap)')\n",
    "plt.xlabel('Jaccard Similarity')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate statistics\n",
    "game_sim_stats = pd.Series(game_similarities).describe()\n",
    "print(\"Statistics of game-game similarities:\")\n",
    "print(game_sim_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "Let's summarize our key findings from the data exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our exploratory data analysis, we've made several important observations:\n",
    "\n",
    "1. **Data Sparsity**: The user-game interaction matrix is extremely sparse, with most users playing only a small fraction of available games. This suggests that collaborative filtering techniques may face challenges and dimensionality reduction approaches like SVD could be beneficial.\n",
    "\n",
    "2. **Playtime Distribution**: There's a wide range of playtime across users and games, with some users playing certain games for thousands of hours. Using playtime as a weighted measure of preference rather than binary interaction could provide more nuanced recommendations.\n",
    "\n",
    "3. **Long-Tail Distribution**: Both user activity and game popularity follow a long-tail distribution, with a small number of games accounting for a large proportion of total playtime. This suggests the need for recommendation techniques that can surface less popular but potentially relevant games.\n",
    "\n",
    "4. **User Similarity**: Users generally have low similarity in their game libraries, indicating diverse gaming preferences. This diversity will necessitate advanced recommendation approaches beyond simple user-user similarity.\n",
    "\n",
    "5. **Genre Preferences**: Users often play games across multiple genres, indicating that cross-genre recommendations might be valuable. The distribution of playtime across genres provides additional insight into user engagement patterns.\n",
    "\n",
    "These findings suggest that our recommendation system should:\n",
    "\n",
    "- Leverage playtime data as a stronger signal of user preference\n",
    "- Use dimensionality reduction techniques to handle sparsity\n",
    "- Incorporate game metadata like genres to enhance recommendations\n",
    "- Consider hybrid approaches that combine collaborative filtering with content-based methods\n",
    "- Balance between recommending popular games and discovering niche titles that match user preferences\n",
    "\n",
    "In the next notebook, we'll preprocess the data based on these insights and prepare it for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Exploratory Results\n",
    "\n",
    "Let's save some key statistics and findings for use in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of key statistics\n",
    "exploration_stats = {\n",
    "    'n_users': n_users,\n",
    "    'n_games': n_games,\n",
    "    'n_interactions': n_interactions,\n",
    "    'sparsity': sparsity,\n",
    "    'avg_games_per_user': user_interactions.mean(),\n",
    "    'median_games_per_user': user_interactions.median(),\n",
    "    'avg_users_per_game': game_interactions.mean(),\n",
    "    'median_users_per_game': game_interactions.median(),\n",
    "    'avg_playtime_per_user_hours': user_playtime.mean() / 60,\n",
    "    'avg_playtime_per_game_hours': game_playtime.mean() / 60\n",
    "}\n",
    "\n",
    "# Save statistics to a JSON file\n",
    "with open('../data/processed/exploration_stats.json', 'w') as f:\n",
    "    json.dump(exploration_stats, f, indent=4)\n",
    "\n",
    "print(\"Saved exploration statistics to '../data/processed/exploration_stats.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
