{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Game Recommender System - Data Exploration\n",
    "\n",
    "This notebook explores the Steam Video Game and Bundle Data from Professor Julian McAuley's research repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "# Check if they exist, otherwise define loading functions here for standalone usage\n",
    "try:\n",
    "    from src.data.loader import load_json_gz, load_json, convert_to_dataframes\n",
    "except ImportError:\n",
    "    # Define functions locally if module import fails\n",
    "    def load_json_gz(filepath):\n",
    "        \"\"\"Load a gzipped JSON file line by line.\"\"\"\n",
    "        data = []\n",
    "        with gzip.open(filepath, 'rt') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        return data\n",
    "    \n",
    "    def load_json(filepath):\n",
    "        \"\"\"Load a JSON file line by line.\"\"\"\n",
    "        data = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        return data\n",
    "    \n",
    "    def convert_to_dataframes(data):\n",
    "        \"\"\"Convert JSON data to pandas DataFrames.\"\"\"\n",
    "        dfs = {}\n",
    "        if 'reviews' in data and data['reviews']:\n",
    "            dfs['reviews'] = pd.DataFrame(data['reviews'])\n",
    "        if 'metadata' in data and data['metadata']:\n",
    "            dfs['metadata'] = pd.DataFrame(data['metadata'])\n",
    "        if 'bundles' in data and data['bundles']:\n",
    "            bundle_rows = []\n",
    "            for bundle in data['bundles']:\n",
    "                for item in bundle.get('items', []):\n",
    "                    bundle_row = {\n",
    "                        'bundle_id': bundle.get('bundle_id'),\n",
    "                        'bundle_name': bundle.get('bundle_name'),\n",
    "                        'bundle_price': bundle.get('bundle_price'),\n",
    "                        'item_id': item.get('item_id'),\n",
    "                        'item_name': item.get('item_name'),\n",
    "                        'genre': item.get('genre')\n",
    "                    }\n",
    "                    bundle_rows.append(bundle_row)\n",
    "            dfs['bundles'] = pd.DataFrame(bundle_rows)\n",
    "        return dfs\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Data\n",
    "\n",
    "First, let's define the paths to our data files and load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = '../data'\n",
    "REVIEWS_PATH = os.path.join(DATA_DIR, 'reviews_v2.json.gz')\n",
    "METADATA_PATH = os.path.join(DATA_DIR, 'items_v2.json.gz')\n",
    "BUNDLES_PATH = os.path.join(DATA_DIR, 'bundles.json')\n",
    "\n",
    "# Check if files exist\n",
    "files_exist = all(os.path.exists(path) for path in [REVIEWS_PATH, METADATA_PATH, BUNDLES_PATH])\n",
    "\n",
    "if not files_exist:\n",
    "    print(\"Some data files are missing. Please run the download_data.py script first.\")\n",
    "    print(\"You can run: python ../scripts/download_data.py\")\n",
    "else:\n",
    "    print(\"All data files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a sample of data for exploration\n",
    "def load_sample_data(reviews_path, metadata_path, bundles_path, sample_size=10000):\n",
    "    \"\"\"Load a sample of data for exploration.\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Load a sample of reviews\n",
    "    print(\"Loading reviews sample...\")\n",
    "    if os.path.exists(reviews_path):\n",
    "        with gzip.open(reviews_path, 'rt') as f:\n",
    "            data['reviews'] = []\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= sample_size:\n",
    "                    break\n",
    "                try:\n",
    "                    data['reviews'].append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    # Load a sample of metadata\n",
    "    print(\"Loading metadata sample...\")\n",
    "    if os.path.exists(metadata_path):\n",
    "        with gzip.open(metadata_path, 'rt') as f:\n",
    "            data['metadata'] = []\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= sample_size // 10:  # Load fewer metadata items\n",
    "                    break\n",
    "                try:\n",
    "                    data['metadata'].append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    # Load bundles\n",
    "    print(\"Loading bundles...\")\n",
    "    if os.path.exists(bundles_path):\n",
    "        data['bundles'] = load_json(bundles_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load a sample of data\n",
    "if files_exist:\n",
    "    sample_data = load_sample_data(REVIEWS_PATH, METADATA_PATH, BUNDLES_PATH)\n",
    "    dfs = convert_to_dataframes(sample_data)\n",
    "    \n",
    "    # Print summary of loaded data\n",
    "    print(\"\\nLoaded data summary:\")\n",
    "    for key, df in dfs.items():\n",
    "        print(f\"{key}: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the Data Structure\n",
    "\n",
    "Let's look at the structure of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine reviews data\n",
    "if 'reviews' in dfs:\n",
    "    print(\"Reviews data columns:\")\n",
    "    print(dfs['reviews'].columns.tolist())\n",
    "    print(\"\\nReviews data sample:\")\n",
    "    display(dfs['reviews'].head())\n",
    "else:\n",
    "    print(\"No reviews data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine metadata\n",
    "if 'metadata' in dfs:\n",
    "    print(\"Metadata columns:\")\n",
    "    print(dfs['metadata'].columns.tolist())\n",
    "    print(\"\\nMetadata sample:\")\n",
    "    display(dfs['metadata'].head())\n",
    "else:\n",
    "    print(\"No metadata loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine bundles data\n",
    "if 'bundles' in dfs:\n",
    "    print(\"Bundles columns:\")\n",
    "    print(dfs['bundles'].columns.tolist())\n",
    "    print(\"\\nBundles sample:\")\n",
    "    display(dfs['bundles'].head())\n",
    "else:\n",
    "    print(\"No bundles data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "Let's analyze the key aspects of the data that will be relevant for building a recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Reviews and Playtime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'reviews' in dfs:\n",
    "    reviews_df = dfs['reviews']\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Number of unique users: {reviews_df['user_id'].nunique()}\")\n",
    "    print(f\"Number of unique games: {reviews_df['item_id'].nunique()}\")\n",
    "    \n",
    "    # Playtime analysis\n",
    "    if 'playtime_forever' in reviews_df.columns:\n",
    "        print(\"\\nPlaytime statistics:\")\n",
    "        print(reviews_df['playtime_forever'].describe())\n",
    "        \n",
    "        # Visualization of playtime distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        reviews_df['playtime_forever'].hist(bins=50)\n",
    "        plt.title('Distribution of Playtime')\n",
    "        plt.xlabel('Playtime (minutes)')\n",
    "        plt.ylabel('Number of users')\n",
    "        plt.xscale('log')  # Use log scale for better visualization\n",
    "        plt.show()\n",
    "    \n",
    "    # Games per user\n",
    "    games_per_user = reviews_df.groupby('user_id')['item_id'].count()\n",
    "    print(\"\\nGames per user statistics:\")\n",
    "    print(games_per_user.describe())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    games_per_user.hist(bins=30)\n",
    "    plt.title('Number of Games per User')\n",
    "    plt.xlabel('Number of games')\n",
    "    plt.ylabel('Number of users')\n",
    "    plt.show()\n",
    "    \n",
    "    # Users per game\n",
    "    users_per_game = reviews_df.groupby('item_id')['user_id'].count()\n",
    "    print(\"\\nUsers per game statistics:\")\n",
    "    print(users_per_game.describe())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    users_per_game.hist(bins=30)\n",
    "    plt.title('Number of Users per Game')\n",
    "    plt.xlabel('Number of users')\n",
    "    plt.ylabel('Number of games')\n",
    "    plt.show()\n",
    "    \n",
    "    # Top games by number of players\n",
    "    top_games = users_per_game.sort_values(ascending=False).head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_games.plot(kind='bar')\n",
    "    plt.title('Top 20 Games by Number of Players')\n",
    "    plt.xlabel('Game ID')\n",
    "    plt.ylabel('Number of players')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Genre Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'metadata' in dfs:\n",
    "    metadata_df = dfs['metadata']\n",
    "    \n",
    "    # Analyze genres if available\n",
    "    if 'genre' in metadata_df.columns:\n",
    "        # Extract all genres\n",
    "        all_genres = []\n",
    "        for genres in metadata_df['genre'].dropna():\n",
    "            if isinstance(genres, str):\n",
    "                all_genres.extend([g.strip() for g in genres.split(',')])\n",
    "        \n",
    "        # Count genre occurrences\n",
    "        genre_counts = pd.Series(all_genres).value_counts()\n",
    "        \n",
    "        print(\"Top 20 genres:\")\n",
    "        print(genre_counts.head(20))\n",
    "        \n",
    "        # Visualize top genres\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        genre_counts.head(15).plot(kind='bar')\n",
    "        plt.title('Top 15 Game Genres')\n",
    "        plt.xlabel('Genre')\n",
    "        plt.ylabel('Number of games')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Bundle Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bundles' in dfs:\n",
    "    bundles_df = dfs['bundles']\n",
    "    \n",
    "    # Analyze bundle sizes\n",
    "    bundle_sizes = bundles_df.groupby('bundle_id')['item_id'].count()\n",
    "    \n",
    "    print(\"Bundle size statistics:\")\n",
    "    print(bundle_sizes.describe())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bundle_sizes.hist(bins=20)\n",
    "    plt.title('Distribution of Bundle Sizes')\n",
    "    plt.xlabel('Number of games in bundle')\n",
    "    plt.ylabel('Number of bundles')\n",
    "    plt.show()\n",
    "    \n",
    "    # Top bundles by size\n",
    "    top_bundles = bundle_sizes.sort_values(ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_bundles.plot(kind='bar')\n",
    "    plt.title('Top 10 Largest Bundles')\n",
    "    plt.xlabel('Bundle ID')\n",
    "    plt.ylabel('Number of games')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a User-Game Interaction Matrix\n",
    "\n",
    "Let's create a small sample of the user-game interaction matrix to see how sparse it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'reviews' in dfs:\n",
    "    reviews_df = dfs['reviews']\n",
    "    \n",
    "    # Take a small subset for visualization\n",
    "    top_users = reviews_df['user_id'].value_counts().head(20).index\n",
    "    top_games = reviews_df['item_id'].value_counts().head(20).index\n",
    "    \n",
    "    small_df = reviews_df[\n",
    "        reviews_df['user_id'].isin(top_users) & \n",
    "        reviews_df['item_id'].isin(top_games)\n",
    "    ]\n",
    "    \n",
    "    # Create a pivot table\n",
    "    if 'playtime_forever' in small_df.columns:\n",
    "        # Use playtime as values\n",
    "        pivot = small_df.pivot_table(\n",
    "            index='user_id',\n",
    "            columns='item_id',\n",
    "            values='playtime_forever',\n",
    "            fill_value=0\n",
    "        )\n",
    "    else:\n",
    "        # Use binary indicators if playtime is not available\n",
    "        small_df['interaction'] = 1\n",
    "        pivot = small_df.pivot_table(\n",
    "            index='user_id',\n",
    "            columns='item_id',\n",
    "            values='interaction',\n",
    "            fill_value=0\n",
    "        )\n",
    "    \n",
    "    # Visualize the matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(pivot > 0, cmap='Blues', cbar=False)\n",
    "    plt.title('User-Game Interaction Matrix (Binary)')\n",
    "    plt.xlabel('Games')\n",
    "    plt.ylabel('Users')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    sparsity = (pivot == 0).sum().sum() / (pivot.shape[0] * pivot.shape[1])\n",
    "    print(f\"Matrix sparsity: {sparsity:.4f} ({sparsity*100:.2f}% of entries are zeros)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Findings and Implications for Recommendation System\n",
    "\n",
    "Based on our exploratory data analysis, here are some key observations and their implications for building a recommendation system:\n",
    "\n",
    "1. **Data Sparsity**: The user-game interaction matrix is extremely sparse, which means we'll need techniques that can handle sparse data well, such as matrix factorization.\n",
    "\n",
    "2. **Playtime Distribution**: Playtime is heavily skewed, with many short plays and few extremely long plays. We may need to normalize or transform playtime data.\n",
    "\n",
    "3. **User and Game Distributions**: There's a large variation in the number of games per user and users per game. This indicates potential cold-start problems for new users or games.\n",
    "\n",
    "4. **Genre Information**: Genre data can be valuable for content-based filtering or hybrid approaches that combine collaborative and content-based methods.\n",
    "\n",
    "5. **Bundles**: Bundle information provides additional context that could be used for package recommendations.\n",
    "\n",
    "In the next notebook, we'll preprocess this data to prepare it for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Handle missing values\n",
    "   - Normalize playtime data\n",
    "   - Filter out users with few interactions and games with few players\n",
    "   - Split data into training and testing sets\n",
    "\n",
    "2. **Model Development**:\n",
    "   - Implement baseline collaborative filtering models\n",
    "   - Implement advanced SVD-based models\n",
    "   - Consider hybrid approaches using genre information\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Measure model performance using metrics like precision@k and hit rate\n",
    "   - Compare different approaches\n",
    "   - Tune hyperparameters for optimal performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
